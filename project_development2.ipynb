{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fa74b8-9fa1-444a-884f-d7def49e0f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 148 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Found 148 images belonging to 2 classes.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.4473 - loss: 2.0629 - val_accuracy: 0.5000 - val_loss: 0.7179\n",
      "Number of detected anomalies: 9\n",
      "Number of refined indices: 139\n",
      "Percentage of anomalies detected: 6.081081081081081\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Dataset Paths\n",
    "train_dir = 'xray_dataset_covid19//train'\n",
    "test_dir = 'xray_dataset_covid19//test'\n",
    "\n",
    "# Image Preprocessing\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_data = data_generator.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "original_labels = train_data.classes.copy()\n",
    "\n",
    "# Data Poisoning\n",
    "def apply_label_flip(labels, flip_rate=0.05):\n",
    "    poisoned_labels = labels.copy()\n",
    "    num_flips = int(len(labels) * flip_rate)\n",
    "    flip_indices = random.sample(range(len(labels)), num_flips)\n",
    "    for idx in flip_indices:\n",
    "        poisoned_labels[idx] = 1 - poisoned_labels[idx]\n",
    "    return poisoned_labels, flip_indices\n",
    "\n",
    "def apply_feature_flip(images, flip_rate=0.05):\n",
    "    poisoned_images = images.copy()\n",
    "    num_flips = int(len(images) * flip_rate)\n",
    "    flip_indices = random.sample(range(len(images)), num_flips)\n",
    "    for idx in flip_indices:\n",
    "        # Simple feature flip (e.g., invert pixel values)\n",
    "        poisoned_images[idx] = 1 - poisoned_images[idx]\n",
    "    return poisoned_images, flip_indices\n",
    "\n",
    "def apply_backdoor(images, labels, target_label=1, backdoor_pattern=(0.8, 0.8, 0.8), position=(0.1, 0.1), size=(0.05, 0.05), backdoor_rate=0.05):\n",
    "    poisoned_images = images.copy()\n",
    "    poisoned_labels = labels.copy()\n",
    "    num_backdoors = int(len(images) * backdoor_rate)\n",
    "    backdoor_indices = random.sample(range(len(images)), num_backdoors)\n",
    "\n",
    "    for idx in backdoor_indices:\n",
    "        img_height, img_width, _ = poisoned_images[idx].shape\n",
    "        x_start = int(position[0] * img_width)\n",
    "        y_start = int(position[1] * img_height)\n",
    "        pattern_width = int(size[0] * img_width)\n",
    "        pattern_height = int(size[1] * img_height)\n",
    "\n",
    "        poisoned_images[idx][y_start:y_start+pattern_height, x_start:x_start+pattern_width] = backdoor_pattern\n",
    "        poisoned_labels[idx] = target_label  # Change label to the target\n",
    "\n",
    "    return poisoned_images, poisoned_labels, backdoor_indices\n",
    "\n",
    "poisoned_labels, flipped_indices = apply_label_flip(original_labels)\n",
    "\n",
    "# Baseline Model Construction and Training\n",
    "def build_cnn(input_shape=(img_height, img_width, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape), # Correct\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "    \n",
    "baseline_model = build_cnn()\n",
    "\n",
    "# Generator with poisoned labels\n",
    "poisoned_train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "poisoned_train_generator.classes = poisoned_labels\n",
    "\n",
    "baseline_model.fit(\n",
    "    poisoned_train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=test_data\n",
    ")\n",
    "\n",
    "def detect_anomalies_batched(generator, anomaly_detector):\n",
    "    anomaly_indices_list =[]\n",
    "    num_batches = len(generator)\n",
    "    for i in range(num_batches):\n",
    "        batch_features, batch_labels = next(generator)\n",
    "        flattened_features = batch_features.reshape(batch_features.shape[0], -1)\n",
    "        if hasattr(anomaly_detector, 'fit_predict'):\n",
    "            anomalies = anomaly_detector.fit_predict(flattened_features)\n",
    "        elif hasattr(anomaly_detector, 'predict'):\n",
    "            anomalies = anomaly_detector.predict(flattened_features)\n",
    "        else:\n",
    "            raise ValueError(\"Anomaly detector must have 'fit_predict' or 'predict' method\")\n",
    "\n",
    "        anomaly_indices = np.where(anomalies == -1)[0]\n",
    "        if len(anomaly_indices) > 0:\n",
    "            global_indices = anomaly_indices + i * generator.batch_size\n",
    "            anomaly_indices_list.extend(global_indices)\n",
    "\n",
    "    return np.array(anomaly_indices_list)\n",
    "\n",
    "# Perform anomaly detection in a memory-efficient way\n",
    "anomaly_detector_if = IsolationForest(contamination=0.05)\n",
    "anomaly_indices_if = detect_anomalies_batched(poisoned_train_generator, anomaly_detector_if)\n",
    "\n",
    "anomaly_detector_km = KMeans(n_clusters=2, random_state=42)\n",
    "anomaly_indices_km = detect_anomalies_batched(poisoned_train_generator, anomaly_detector_km)\n",
    "\n",
    "combined_anomaly_indices = np.union1d(anomaly_indices_if, anomaly_indices_km)\n",
    "\n",
    "print(f\"Number of detected anomalies: {len(combined_anomaly_indices)}\")\n",
    "\n",
    "# Robust Model Training\n",
    "combined_anomaly_set = set(combined_anomaly_indices)\n",
    "refined_indices = [i for i in range(len(original_labels)) if i not in combined_anomaly_set]\n",
    "\n",
    "print(f\"Number of refined indices: {len(refined_indices)}\")\n",
    "\n",
    "print(f\"Percentage of anomalies detected: {len(combined_anomaly_indices)*100/(len(combined_anomaly_indices)+len(refined_indices))}\")\n",
    "\n",
    "\n",
    "def refined_generator(generator, indices, batch_size):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    generator.reset()\n",
    "    for features, labels in generator:\n",
    "        all_features.append(features)\n",
    "        all_labels.append(labels)\n",
    "    all_features = np.concatenate(all_features)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "\n",
    "    num_samples = len(indices)\n",
    "    while True:\n",
    "        batch_indices = np.random.choice(num_samples, batch_size, replace=False)\n",
    "        selected_indices = [indices[i] for i in batch_indices]\n",
    "\n",
    "        batch_x = all_features[selected_indices]\n",
    "        batch_y = all_labels[selected_indices]\n",
    "\n",
    "        yield batch_x, batch_y\n",
    "\n",
    "refined_train_generator = refined_generator(poisoned_train_generator, refined_indices, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30e8d06-74d0-40de-af30-0c5002535b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "robust_model = build_cnn()\n",
    "\n",
    "# Training with refined data\n",
    "epochs = 1\n",
    "steps_per_epoch = len(refined_indices) // batch_size\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for step in range(steps_per_epoch):\n",
    "        batch_features, batch_labels = next(refined_train_generator)\n",
    "        print(f\"Batch features shape: {batch_features.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        robust_model.train_on_batch(batch_features, batch_labels)\n",
    "\n",
    "# Evaluation\n",
    "_, baseline_accuracy = baseline_model.evaluate(test_data)\n",
    "_, robust_accuracy = robust_model.evaluate(test_data)\n",
    "\n",
    "print(f\"Baseline Accuracy (Poisoned): {baseline_accuracy}\")\n",
    "print(f\"Robust Model Accuracy: {robust_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c7db3-06be-41ce-beb2-fcd65126b9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
